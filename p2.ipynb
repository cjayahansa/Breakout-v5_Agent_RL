{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acbb796c-66d5-4e34-aaa1-6a1ac2e88998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (1.2.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (2.2.6)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (2.5.1+cu121)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (3.10.7)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
      "Requirement already satisfied: pygame in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (2.20.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (14.2.0)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (0.11.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from stable-baselines3[extra]) (12.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium<1.3.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.20.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.9)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (6.33.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (80.9.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8dd5618-0b7e-4650-8b4f-1a190e47c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aae6237-f0b0-466f-8cce-757177f37d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ale-py in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: gymnasium[atari] in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium[atari] ale-py matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be4ed61-9be8-419e-bdd1-4616ac546ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f7a225-7d5f-41f6-8918-b1ef25632aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda activate myenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5e0958-2240-479d-9805-a1c7683596d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\myenv\\python.exe: No module named ale_py.import_roms\n"
     ]
    }
   ],
   "source": [
    "!python -m ale_py.import_roms \"C:\\Users\\hp\\anaconda3\\envs\\myenv\\Lib\\site-packages\\AutoROM\\roms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cac431a-85d0-4c40-b2ff-2e9af9af28f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[accept-rom-license,atari] in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n",
      "Requirement already satisfied: ale_py>=0.9 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[accept-rom-license,atari]) (0.11.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: gymnasium 1.2.1 does not provide the extra 'accept-rom-license'\n"
     ]
    }
   ],
   "source": [
    "pip install \"gymnasium[atari,accept-rom-license]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4504bcf9-fe1c-4562-8c86-410294745894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\anaconda3\\envs\\myenv\\python.exe: No module named AutoROM.__main__; 'AutoROM' is a package and cannot be directly executed\n"
     ]
    }
   ],
   "source": [
    "!python -m AutoROM --accept-license\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cafaf6b9-de5f-4910-95e7-9655436af531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available ALE environments:\n",
      "ALE/Adventure-v5\n",
      "ALE/AirRaid-v5\n",
      "ALE/Alien-v5\n",
      "ALE/Amidar-v5\n",
      "ALE/Assault-v5\n",
      "ALE/Asterix-v5\n",
      "ALE/Asteroids-v5\n",
      "ALE/Atlantis2-v5\n",
      "ALE/Atlantis-v5\n",
      "ALE/Backgammon-v5\n",
      "ALE/BankHeist-v5\n",
      "ALE/BasicMath-v5\n",
      "ALE/BattleZone-v5\n",
      "ALE/BeamRider-v5\n",
      "ALE/Berzerk-v5\n",
      "ALE/Blackjack-v5\n",
      "ALE/Bowling-v5\n",
      "ALE/Boxing-v5\n",
      "ALE/Breakout-v5\n",
      "ALE/Carnival-v5\n",
      "ALE/Casino-v5\n",
      "ALE/Centipede-v5\n",
      "ALE/ChopperCommand-v5\n",
      "ALE/CrazyClimber-v5\n",
      "ALE/Crossbow-v5\n",
      "ALE/Darkchambers-v5\n",
      "ALE/Defender-v5\n",
      "ALE/DemonAttack-v5\n",
      "ALE/DonkeyKong-v5\n",
      "ALE/DoubleDunk-v5\n",
      "ALE/Earthworld-v5\n",
      "ALE/ElevatorAction-v5\n",
      "ALE/Enduro-v5\n",
      "ALE/Entombed-v5\n",
      "ALE/Et-v5\n",
      "ALE/FishingDerby-v5\n",
      "ALE/FlagCapture-v5\n",
      "ALE/Freeway-v5\n",
      "ALE/Frogger-v5\n",
      "ALE/Frostbite-v5\n",
      "ALE/Galaxian-v5\n",
      "ALE/Gopher-v5\n",
      "ALE/Gravitar-v5\n",
      "ALE/Hangman-v5\n",
      "ALE/HauntedHouse-v5\n",
      "ALE/Hero-v5\n",
      "ALE/HumanCannonball-v5\n",
      "ALE/IceHockey-v5\n",
      "ALE/Jamesbond-v5\n",
      "ALE/JourneyEscape-v5\n",
      "ALE/Kaboom-v5\n",
      "ALE/Kangaroo-v5\n",
      "ALE/KeystoneKapers-v5\n",
      "ALE/KingKong-v5\n",
      "ALE/Klax-v5\n",
      "ALE/Koolaid-v5\n",
      "ALE/Krull-v5\n",
      "ALE/KungFuMaster-v5\n",
      "ALE/LaserGates-v5\n",
      "ALE/LostLuggage-v5\n",
      "ALE/MarioBros-v5\n",
      "ALE/MiniatureGolf-v5\n",
      "ALE/MontezumaRevenge-v5\n",
      "ALE/MrDo-v5\n",
      "ALE/MsPacman-v5\n",
      "ALE/NameThisGame-v5\n",
      "ALE/Othello-v5\n",
      "ALE/Pacman-v5\n",
      "ALE/Phoenix-v5\n",
      "ALE/Pitfall2-v5\n",
      "ALE/Pitfall-v5\n",
      "ALE/Pong-v5\n",
      "ALE/Pooyan-v5\n",
      "ALE/PrivateEye-v5\n",
      "ALE/Qbert-v5\n",
      "ALE/Riverraid-v5\n",
      "ALE/RoadRunner-v5\n",
      "ALE/Robotank-v5\n",
      "ALE/Seaquest-v5\n",
      "ALE/SirLancelot-v5\n",
      "ALE/Skiing-v5\n",
      "ALE/Solaris-v5\n",
      "ALE/SpaceInvaders-v5\n",
      "ALE/SpaceWar-v5\n",
      "ALE/StarGunner-v5\n",
      "ALE/Superman-v5\n",
      "ALE/Surround-v5\n",
      "ALE/Tennis-v5\n",
      "ALE/Tetris-v5\n",
      "ALE/TicTacToe3D-v5\n",
      "ALE/TimePilot-v5\n",
      "ALE/Trondead-v5\n",
      "ALE/Turmoil-v5\n",
      "ALE/Tutankham-v5\n",
      "ALE/UpNDown-v5\n",
      "ALE/Venture-v5\n",
      "ALE/VideoCheckers-v5\n",
      "ALE/VideoChess-v5\n",
      "ALE/VideoCube-v5\n",
      "ALE/VideoPinball-v5\n",
      "ALE/WizardOfWor-v5\n",
      "ALE/WordZapper-v5\n",
      "ALE/YarsRevenge-v5\n",
      "ALE/Zaxxon-v5\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "\n",
    "# Register ALE environments manually\n",
    "gym.envs.registration.register_envs(ale_py)\n",
    "\n",
    "# List available Atari games\n",
    "print(\"Available ALE environments:\")\n",
    "for env_id in gym.envs.registry.keys():\n",
    "    if env_id.startswith(\"ALE/\"):\n",
    "        print(env_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc6f9ba-4d91-4708-a779-25039cc76ec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gymnasium.envs.atari'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01matari\u001b[39;00m  \u001b[38;5;66;03m# <---- this line registers the Atari environments\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_id \u001b[38;5;129;01min\u001b[39;00m gym\u001b[38;5;241m.\u001b[39menvs\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m env_id\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALE/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gymnasium.envs.atari'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import gymnasium.envs.atari  # <---- this line registers the Atari environments\n",
    "\n",
    "for env_id in gym.envs.registry.keys():\n",
    "    if env_id.startswith(\"ALE/\"):\n",
    "        print(env_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9198488-64cf-4a97-901e-734e46c25996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALE/Adventure-v5\n",
      "ALE/AirRaid-v5\n",
      "ALE/Alien-v5\n",
      "ALE/Amidar-v5\n",
      "ALE/Assault-v5\n",
      "ALE/Asterix-v5\n",
      "ALE/Asteroids-v5\n",
      "ALE/Atlantis2-v5\n",
      "ALE/Atlantis-v5\n",
      "ALE/Backgammon-v5\n",
      "ALE/BankHeist-v5\n",
      "ALE/BasicMath-v5\n",
      "ALE/BattleZone-v5\n",
      "ALE/BeamRider-v5\n",
      "ALE/Berzerk-v5\n",
      "ALE/Blackjack-v5\n",
      "ALE/Bowling-v5\n",
      "ALE/Boxing-v5\n",
      "ALE/Breakout-v5\n",
      "ALE/Carnival-v5\n",
      "ALE/Casino-v5\n",
      "ALE/Centipede-v5\n",
      "ALE/ChopperCommand-v5\n",
      "ALE/CrazyClimber-v5\n",
      "ALE/Crossbow-v5\n",
      "ALE/Darkchambers-v5\n",
      "ALE/Defender-v5\n",
      "ALE/DemonAttack-v5\n",
      "ALE/DonkeyKong-v5\n",
      "ALE/DoubleDunk-v5\n",
      "ALE/Earthworld-v5\n",
      "ALE/ElevatorAction-v5\n",
      "ALE/Enduro-v5\n",
      "ALE/Entombed-v5\n",
      "ALE/Et-v5\n",
      "ALE/FishingDerby-v5\n",
      "ALE/FlagCapture-v5\n",
      "ALE/Freeway-v5\n",
      "ALE/Frogger-v5\n",
      "ALE/Frostbite-v5\n",
      "ALE/Galaxian-v5\n",
      "ALE/Gopher-v5\n",
      "ALE/Gravitar-v5\n",
      "ALE/Hangman-v5\n",
      "ALE/HauntedHouse-v5\n",
      "ALE/Hero-v5\n",
      "ALE/HumanCannonball-v5\n",
      "ALE/IceHockey-v5\n",
      "ALE/Jamesbond-v5\n",
      "ALE/JourneyEscape-v5\n",
      "ALE/Kaboom-v5\n",
      "ALE/Kangaroo-v5\n",
      "ALE/KeystoneKapers-v5\n",
      "ALE/KingKong-v5\n",
      "ALE/Klax-v5\n",
      "ALE/Koolaid-v5\n",
      "ALE/Krull-v5\n",
      "ALE/KungFuMaster-v5\n",
      "ALE/LaserGates-v5\n",
      "ALE/LostLuggage-v5\n",
      "ALE/MarioBros-v5\n",
      "ALE/MiniatureGolf-v5\n",
      "ALE/MontezumaRevenge-v5\n",
      "ALE/MrDo-v5\n",
      "ALE/MsPacman-v5\n",
      "ALE/NameThisGame-v5\n",
      "ALE/Othello-v5\n",
      "ALE/Pacman-v5\n",
      "ALE/Phoenix-v5\n",
      "ALE/Pitfall2-v5\n",
      "ALE/Pitfall-v5\n",
      "ALE/Pong-v5\n",
      "ALE/Pooyan-v5\n",
      "ALE/PrivateEye-v5\n",
      "ALE/Qbert-v5\n",
      "ALE/Riverraid-v5\n",
      "ALE/RoadRunner-v5\n",
      "ALE/Robotank-v5\n",
      "ALE/Seaquest-v5\n",
      "ALE/SirLancelot-v5\n",
      "ALE/Skiing-v5\n",
      "ALE/Solaris-v5\n",
      "ALE/SpaceInvaders-v5\n",
      "ALE/SpaceWar-v5\n",
      "ALE/StarGunner-v5\n",
      "ALE/Superman-v5\n",
      "ALE/Surround-v5\n",
      "ALE/Tennis-v5\n",
      "ALE/Tetris-v5\n",
      "ALE/TicTacToe3D-v5\n",
      "ALE/TimePilot-v5\n",
      "ALE/Trondead-v5\n",
      "ALE/Turmoil-v5\n",
      "ALE/Tutankham-v5\n",
      "ALE/UpNDown-v5\n",
      "ALE/Venture-v5\n",
      "ALE/VideoCheckers-v5\n",
      "ALE/VideoChess-v5\n",
      "ALE/VideoCube-v5\n",
      "ALE/VideoPinball-v5\n",
      "ALE/WizardOfWor-v5\n",
      "ALE/WordZapper-v5\n",
      "ALE/YarsRevenge-v5\n",
      "ALE/Zaxxon-v5\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "for env_id in gym.envs.registry.keys():\n",
    "    if env_id.startswith(\"ALE/\"):\n",
    "        print(env_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4744f33-2ee4-4376-8e80-61c719180977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALE/Adventure-v5\n",
      "ALE/AirRaid-v5\n",
      "ALE/Alien-v5\n",
      "ALE/Amidar-v5\n",
      "ALE/Assault-v5\n",
      "ALE/Asterix-v5\n",
      "ALE/Asteroids-v5\n",
      "ALE/Atlantis2-v5\n",
      "ALE/Atlantis-v5\n",
      "ALE/Backgammon-v5\n",
      "ALE/BankHeist-v5\n",
      "ALE/BasicMath-v5\n",
      "ALE/BattleZone-v5\n",
      "ALE/BeamRider-v5\n",
      "ALE/Berzerk-v5\n",
      "ALE/Blackjack-v5\n",
      "ALE/Bowling-v5\n",
      "ALE/Boxing-v5\n",
      "ALE/Breakout-v5\n",
      "ALE/Carnival-v5\n",
      "ALE/Casino-v5\n",
      "ALE/Centipede-v5\n",
      "ALE/ChopperCommand-v5\n",
      "ALE/CrazyClimber-v5\n",
      "ALE/Crossbow-v5\n",
      "ALE/Darkchambers-v5\n",
      "ALE/Defender-v5\n",
      "ALE/DemonAttack-v5\n",
      "ALE/DonkeyKong-v5\n",
      "ALE/DoubleDunk-v5\n",
      "ALE/Earthworld-v5\n",
      "ALE/ElevatorAction-v5\n",
      "ALE/Enduro-v5\n",
      "ALE/Entombed-v5\n",
      "ALE/Et-v5\n",
      "ALE/FishingDerby-v5\n",
      "ALE/FlagCapture-v5\n",
      "ALE/Freeway-v5\n",
      "ALE/Frogger-v5\n",
      "ALE/Frostbite-v5\n",
      "ALE/Galaxian-v5\n",
      "ALE/Gopher-v5\n",
      "ALE/Gravitar-v5\n",
      "ALE/Hangman-v5\n",
      "ALE/HauntedHouse-v5\n",
      "ALE/Hero-v5\n",
      "ALE/HumanCannonball-v5\n",
      "ALE/IceHockey-v5\n",
      "ALE/Jamesbond-v5\n",
      "ALE/JourneyEscape-v5\n",
      "ALE/Kaboom-v5\n",
      "ALE/Kangaroo-v5\n",
      "ALE/KeystoneKapers-v5\n",
      "ALE/KingKong-v5\n",
      "ALE/Klax-v5\n",
      "ALE/Koolaid-v5\n",
      "ALE/Krull-v5\n",
      "ALE/KungFuMaster-v5\n",
      "ALE/LaserGates-v5\n",
      "ALE/LostLuggage-v5\n",
      "ALE/MarioBros-v5\n",
      "ALE/MiniatureGolf-v5\n",
      "ALE/MontezumaRevenge-v5\n",
      "ALE/MrDo-v5\n",
      "ALE/MsPacman-v5\n",
      "ALE/NameThisGame-v5\n",
      "ALE/Othello-v5\n",
      "ALE/Pacman-v5\n",
      "ALE/Phoenix-v5\n",
      "ALE/Pitfall2-v5\n",
      "ALE/Pitfall-v5\n",
      "ALE/Pong-v5\n",
      "ALE/Pooyan-v5\n",
      "ALE/PrivateEye-v5\n",
      "ALE/Qbert-v5\n",
      "ALE/Riverraid-v5\n",
      "ALE/RoadRunner-v5\n",
      "ALE/Robotank-v5\n",
      "ALE/Seaquest-v5\n",
      "ALE/SirLancelot-v5\n",
      "ALE/Skiing-v5\n",
      "ALE/Solaris-v5\n",
      "ALE/SpaceInvaders-v5\n",
      "ALE/SpaceWar-v5\n",
      "ALE/StarGunner-v5\n",
      "ALE/Superman-v5\n",
      "ALE/Surround-v5\n",
      "ALE/Tennis-v5\n",
      "ALE/Tetris-v5\n",
      "ALE/TicTacToe3D-v5\n",
      "ALE/TimePilot-v5\n",
      "ALE/Trondead-v5\n",
      "ALE/Turmoil-v5\n",
      "ALE/Tutankham-v5\n",
      "ALE/UpNDown-v5\n",
      "ALE/Venture-v5\n",
      "ALE/VideoCheckers-v5\n",
      "ALE/VideoChess-v5\n",
      "ALE/VideoCube-v5\n",
      "ALE/VideoPinball-v5\n",
      "ALE/WizardOfWor-v5\n",
      "ALE/WordZapper-v5\n",
      "ALE/YarsRevenge-v5\n",
      "ALE/Zaxxon-v5\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "for env_id in gym.envs.registry.keys():\n",
    "    if env_id.startswith(\"ALE/\"):\n",
    "        print(env_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9626321-df1d-45dc-8185-70030011a8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[atari] in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (2.2.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (0.0.4)\n",
      "Requirement already satisfied: ale_py>=0.9 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from gymnasium[atari]) (0.11.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"gymnasium[atari]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaa1d4fc-3eaa-4c91-93bb-552e2bd2c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Correct environment name for Gymnasium\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "\n",
    "# observation, info = env.reset()\n",
    "\n",
    "# for _ in range(500):\n",
    "#     action = env.action_space.sample()  # random action\n",
    "#     observation, reward, terminated, truncated, info = env.step(action)\n",
    "#     if terminated or truncated:\n",
    "#         observation, info = env.reset()\n",
    "\n",
    "# env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43cd6dae-7f78-4ed2-8bb4-8aa628b8d4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ab7efb2-b808-4907-b7dd-eb91ebf74a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a8717a9-3163-4c2d-be32-170c54933b09",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OrderEnforcing' object has no attribute 'closs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcloss\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OrderEnforcing' object has no attribute 'closs'"
     ]
    }
   ],
   "source": [
    "env.closs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ca8012b-4729-4efd-addd-65326f1e8387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: 1.0\n",
      "Episode: 2, Score: 0.0\n",
      "Episode: 3, Score: 0.0\n",
      "Episode: 4, Score: 2.0\n",
      "Episode: 5, Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes + 1):\n",
    "    observation, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    score = 0\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward  # <- accumulate reward into score\n",
    "\n",
    "    print(f'Episode: {episode}, Score: {score}')\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a502f5ee-b580-46dd-b46e-d5580afdaaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f4fbc4b-dfe0-4381-bd75-68cbae5d485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "\n",
    "# Create 4 parallel ALE/Breakout-v5 environments\n",
    "env = make_vec_env(\"ALE/Breakout-v5\", n_envs=4, seed=0)\n",
    "\n",
    "# Stack 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d453d88d-45d4-4cbd-8586-4c6ebbba71ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to Training\\Logs\\A2C_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "\n",
    "def make_env():\n",
    "    return gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\") \n",
    "    \n",
    "env = DummyVecEnv([make_env for _ in range(4)])\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "log_path = os.path.join(\"Training\", \"Logs\")\n",
    "\n",
    "model = A2C(\"CnnPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
    "\n",
    "model.learn(total_timesteps=1000)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "119ba119-4eab-4f87-b717-e3ce9b2e2928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\A2C_2\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 36       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | -0.272   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 149      |\n",
      "|    policy_loss        | -0.023   |\n",
      "|    value_loss         | 0.0105   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 36       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 110      |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.465    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 249      |\n",
      "|    policy_loss        | 0.283    |\n",
      "|    value_loss         | 0.161    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.342    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 349      |\n",
      "|    policy_loss        | -0.00986 |\n",
      "|    value_loss         | 0.00068  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 206      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | -0.381   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 449      |\n",
      "|    policy_loss        | 0.073    |\n",
      "|    value_loss         | 0.019    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.37    |\n",
      "|    explained_variance | 0.457    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 549      |\n",
      "|    policy_loss        | -0.0347  |\n",
      "|    value_loss         | 0.00389  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | 0.601    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 649      |\n",
      "|    policy_loss        | -0.02    |\n",
      "|    value_loss         | 0.000764 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 355      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | 0.218    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 749      |\n",
      "|    policy_loss        | 0.0333   |\n",
      "|    value_loss         | 0.0227   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 405      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.351    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 849      |\n",
      "|    policy_loss        | -0.0126  |\n",
      "|    value_loss         | 0.00369  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 456      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.327    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 949      |\n",
      "|    policy_loss        | 0.324    |\n",
      "|    value_loss         | 0.146    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 503      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.963    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1049     |\n",
      "|    policy_loss        | 0.00762  |\n",
      "|    value_loss         | 0.00403  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 551      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.988   |\n",
      "|    explained_variance | 0.916    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1149     |\n",
      "|    policy_loss        | 0.0242   |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 598      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.993   |\n",
      "|    explained_variance | 0.869    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1249     |\n",
      "|    policy_loss        | -0.0478  |\n",
      "|    value_loss         | 0.0044   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 645      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.24    |\n",
      "|    explained_variance | 0.95     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1349     |\n",
      "|    policy_loss        | 0.0223   |\n",
      "|    value_loss         | 0.00307  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 698      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.28    |\n",
      "|    explained_variance | 0.932    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1449     |\n",
      "|    policy_loss        | 0.029    |\n",
      "|    value_loss         | 0.0118   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 757      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.25    |\n",
      "|    explained_variance | -0.0697  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1549     |\n",
      "|    policy_loss        | -0.0662  |\n",
      "|    value_loss         | 0.0136   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 819      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0.96     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1649     |\n",
      "|    policy_loss        | -0.032   |\n",
      "|    value_loss         | 0.00335  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 879      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1     |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1749     |\n",
      "|    policy_loss        | 0.0067   |\n",
      "|    value_loss         | 0.00019  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 939      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0.855    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1849     |\n",
      "|    policy_loss        | -0.0705  |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 1001     |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.936   |\n",
      "|    explained_variance | 0.979    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1949     |\n",
      "|    policy_loss        | 0.015    |\n",
      "|    value_loss         | 0.00889  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 1061     |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | -0.0617  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2049     |\n",
      "|    policy_loss        | -0.0288  |\n",
      "|    value_loss         | 0.00431  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 1121     |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.97     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2149     |\n",
      "|    policy_loss        | -0.0226  |\n",
      "|    value_loss         | 0.00632  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 1180     |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2249     |\n",
      "|    policy_loss        | 0.00327  |\n",
      "|    value_loss         | 0.000117 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 1238     |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.732    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2349     |\n",
      "|    policy_loss        | 0.0992   |\n",
      "|    value_loss         | 0.0185   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 1296     |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.856    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2449     |\n",
      "|    policy_loss        | -0.0612  |\n",
      "|    value_loss         | 0.0518   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 36       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 1355     |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.996   |\n",
      "|    explained_variance | 0.978    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2549     |\n",
      "|    policy_loss        | -0.0604  |\n",
      "|    value_loss         | 0.00517  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 36       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 1413     |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.819   |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2649     |\n",
      "|    policy_loss        | -0.0083  |\n",
      "|    value_loss         | 0.00321  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 36       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 1462     |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.866   |\n",
      "|    explained_variance | 0.646    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2749     |\n",
      "|    policy_loss        | 0.0203   |\n",
      "|    value_loss         | 0.0042   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 1505     |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2849     |\n",
      "|    policy_loss        | -0.0199  |\n",
      "|    value_loss         | 0.00277  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 1550     |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.37    |\n",
      "|    explained_variance | 0.198    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2949     |\n",
      "|    policy_loss        | 0.325    |\n",
      "|    value_loss         | 0.261    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 1593     |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.00857  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3049     |\n",
      "|    policy_loss        | -0.0687  |\n",
      "|    value_loss         | 0.00644  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 37       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 1636     |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.08    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3149     |\n",
      "|    policy_loss        | 0.0103   |\n",
      "|    value_loss         | 0.000646 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 1678     |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.36    |\n",
      "|    explained_variance | 0.972    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3249     |\n",
      "|    policy_loss        | -0.0348  |\n",
      "|    value_loss         | 0.00346  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 1721     |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.33    |\n",
      "|    explained_variance | 0.995    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3349     |\n",
      "|    policy_loss        | -0.0209  |\n",
      "|    value_loss         | 0.000681 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 1764     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.926    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3449     |\n",
      "|    policy_loss        | 0.0729   |\n",
      "|    value_loss         | 0.0141   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 1806     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.22    |\n",
      "|    explained_variance | 0.998    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3549     |\n",
      "|    policy_loss        | -0.0048  |\n",
      "|    value_loss         | 0.000267 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 38       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 1849     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.05    |\n",
      "|    explained_variance | 0.996    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3649     |\n",
      "|    policy_loss        | 0.0107   |\n",
      "|    value_loss         | 0.000974 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 1892     |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.16    |\n",
      "|    explained_variance | 0.987    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3749     |\n",
      "|    policy_loss        | -0.0155  |\n",
      "|    value_loss         | 0.00253  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 1935     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3849     |\n",
      "|    policy_loss        | -0.00863 |\n",
      "|    value_loss         | 9.49e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 1978     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.844   |\n",
      "|    explained_variance | 0.889    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3949     |\n",
      "|    policy_loss        | -0.0103  |\n",
      "|    value_loss         | 0.0102   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 2021     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.879   |\n",
      "|    explained_variance | -0.0853  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4049     |\n",
      "|    policy_loss        | -0.177   |\n",
      "|    value_loss         | 0.243    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 2063     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.669   |\n",
      "|    explained_variance | 0.991    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4149     |\n",
      "|    policy_loss        | -0.0193  |\n",
      "|    value_loss         | 0.000958 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 39       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 2106     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.895   |\n",
      "|    explained_variance | 0.997    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4249     |\n",
      "|    policy_loss        | 0.000298 |\n",
      "|    value_loss         | 0.000311 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 2149     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.877   |\n",
      "|    explained_variance | 0.905    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4349     |\n",
      "|    policy_loss        | -0.0471  |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 2191     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.874   |\n",
      "|    explained_variance | 0.93     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4449     |\n",
      "|    policy_loss        | 0.102    |\n",
      "|    value_loss         | 0.0237   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 2234     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.955   |\n",
      "|    explained_variance | 0.543    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4549     |\n",
      "|    policy_loss        | 0.0617   |\n",
      "|    value_loss         | 0.0904   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 2277     |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.3     |\n",
      "|    explained_variance | 0.229    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4649     |\n",
      "|    policy_loss        | -0.0474  |\n",
      "|    value_loss         | 0.0447   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 2320     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.19    |\n",
      "|    explained_variance | 0.845    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4749     |\n",
      "|    policy_loss        | 0.0419   |\n",
      "|    value_loss         | 0.0142   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 2362     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.93     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4849     |\n",
      "|    policy_loss        | 0.00644  |\n",
      "|    value_loss         | 0.00274  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 2405     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.878   |\n",
      "|    explained_variance | 0.986    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4949     |\n",
      "|    policy_loss        | -0.0236  |\n",
      "|    value_loss         | 0.00337  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 40       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 2448     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.964    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5049     |\n",
      "|    policy_loss        | 0.0461   |\n",
      "|    value_loss         | 0.00822  |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x223f91db350>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "113d349d-3c04-43d9-853d-3704675a622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = os.path.join('Training','saved Models','A2C_Breakout_Model')\n",
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b03c6dd-4186-49d6-84ff-e323f2a1ac68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1faa649b-d9ce-4eaa-9f8a-6482b7f2f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path=r\"C:\\Users\\hp\\Desktop\\work\\ML\\RL\\Training\\Saved Models\\A2C_Breakout_Model.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67dc3d6b-7767-4404-a1e4-62e14d0d3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C.load(a2c_path)  # no env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f070425-21b2-497f-a8b4-dda6a2499f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment\n",
    "obs = env.reset()  # obs shape: (n_envs, n_channels, height, width)\n",
    "\n",
    "# Predict an action\n",
    "action, _states = model.predict(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb5e0414-3bd9-4fe1-b216-461c8a01f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "env = make_vec_env(\"ALE/Breakout-v5\", n_envs=1, seed=0)\n",
    "\n",
    "env = VecFrameStack(env, n_stack=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fdb16-85c5-487e-855f-179a61155822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n",
      "Episode 1 finished with reward: 3.0\n",
      "Episode 2 finished with reward: 7.0\n",
      "Episode 3 finished with reward: 2.0\n",
      "Episode 4 finished with reward: 5.0\n",
      "Episode 5 finished with reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import time\n",
    "\n",
    "a2c_path=r\"C:\\Users\\hp\\Desktop\\work\\ML\\RL\\Training\\Saved Models\\A2C_Breakout_Model.zip\"  # <--- replace with your actual file path\n",
    "\n",
    "def make_env():\n",
    "    return gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")  # human for GUI rendering\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "model = A2C.load(a2c_path, env=env)\n",
    "\n",
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs = env.reset()  # VecEnv returns only obs\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)  # Use obs directly\n",
    "        obs, rewards, dones, infos = env.step(action)\n",
    "        total_reward += rewards[0]  # rewards is a vector for all environments\n",
    "        env.render()  # Show the game\n",
    "        time.sleep(0.01)  # Optional: slow down rendering for visibility\n",
    "\n",
    "        if dones[0]:\n",
    "            break\n",
    "\n",
    "    print(f\"Episode {episode} finished with reward: {total_reward}\")\n",
    "\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10, render=False)\n",
    "print(f\"Evaluation over 10 episodes: mean={mean_reward:.2f}, std={std_reward:.2f}\")\n",
    "\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0db6e-47eb-4f0f-8461-21ec285343d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e31ed0-facc-4b84-b100-fef83c1d56cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
